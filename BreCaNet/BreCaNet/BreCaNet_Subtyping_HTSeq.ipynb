{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import csv\n",
    "import pandas as pd\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath = '/Users/ursulawidocki/Desktop/BreCaNet/Data/gdc_download_HTSeq' #zipped file path\n",
    "dataNewFolder = '/Users/ursulawidocki/Desktop/BreCaNet/Data/processedTCGA_HTSeq'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzips the expression data dn creates a folder (processedTCGA_832) of the unzipped files \n",
    "# Gets the codes of the patient folders and expression files\n",
    "\n",
    "folderIDs = list() # codes of the patient IDs on the folder\n",
    "indivList = list() # codes of the patients' expression file\n",
    "\n",
    "for fileName in os.listdir(dataPath):\n",
    "    if fileName == '.DS_Store' or fileName == 'MANIFEST.txt':\n",
    "        continue\n",
    "        \n",
    "    else:\n",
    "        folderIDs.append(fileName)\n",
    "        \n",
    "    newPath = dataPath + '/' + fileName\n",
    "    \n",
    "    # goes into the individual folder\n",
    "    for indivName in os.listdir(newPath):\n",
    "        if (indivName == '.DS_Store') or (indivName == 'MANIFEST.txt') or (indivName == 'annotations.txt'):\n",
    "            continue\n",
    "        filePath = newPath + '/' + indivName\n",
    "        \n",
    "        fileEnding = indivName[-3] + indivName[-2] + indivName[-1]\n",
    "        if(fileEnding == '.gz'):\n",
    "            with gzip.open(filePath, 'rb') as f_in:\n",
    "                newFilePath = dataNewFolder + '/' + indivName[0:-3]\n",
    "                indivList.append(indivName[0:-3])\n",
    "                \n",
    "                with open(newFilePath, 'wb') as f_out:\n",
    "                    shutil.copyfileobj(f_in, f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "832\n"
     ]
    }
   ],
   "source": [
    "## Makes file of folder names\n",
    "\n",
    "folderIDPath = '/Users/ursulawidocki/Desktop/BreCaNet/Data/foldIDList_HTSeq.txt'\n",
    "folderFile = open(folderIDPath, \"w+\")\n",
    "for i in range(0, 832):\n",
    "    newLineFolder = folderIDs[i] + \"\\n\"\n",
    "    \n",
    "    folderFile.write(newLineFolder)\n",
    "    \n",
    "folderFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Gets folder codes from expression data\n",
    "folderIDPath = '/Users/ursulawidocki/Desktop/BreCaNet/Data/foldIDList_HTSeq.txt'\n",
    "folders = pd.read_csv(folderIDPath, delimiter = '\\t', header = None)\n",
    "folders_list = list(folders[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "714\n",
      "714\n"
     ]
    }
   ],
   "source": [
    "## Reads in metadata\n",
    "# gets file_id and case_id\n",
    "\n",
    "metaPath = '/Users/ursulawidocki/Desktop/BreCaNet/Data/metadata.cart.HTSeq.json' # the same\n",
    "\n",
    "file_id = list()\n",
    "f = 1\n",
    "case_id = list()\n",
    "temp_case_len = 0\n",
    "old_case_len = 0\n",
    "with open(metaPath, \"r\") as file:\n",
    "    for line in file.readlines():\n",
    "            \n",
    "        \n",
    "        if(\"case_id\" in line) and (line.strip().split(\"\\\"\")[3] not in case_id):\n",
    "            old_case_len = len(case_id)\n",
    "            case = line.strip().split(\"\\\"\")[3]\n",
    "            case_id.append(case)\n",
    "            temp_case_len = len(case_id)\n",
    "            \n",
    "        if (\"file_id\" in line) and (old_case_len < temp_case_len):\n",
    "            item = line.strip().split(\"\\\"\")[3]\n",
    "            file_id.append(item)\n",
    "            old_case_len = len(case_id)\n",
    "\n",
    "print(len(file_id))\n",
    "print(len(set(case_id)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1097\n",
      "1097\n"
     ]
    }
   ],
   "source": [
    "## Gets uuid and barcodes of the patients from clinical data\n",
    "\n",
    "# reads in clinical information to link patients with their barcode\n",
    "clinicalPath = '/Users/ursulawidocki/Desktop/BreCaNet/Data/gdc_download_clinical_832/8162d394-8b64-4da2-9f5b-d164c54b9608/nationwidechildrens.org_clinical_patient_brca.txt'\n",
    "clinical_df = pd.read_csv(clinicalPath, delimiter = '\\t')\n",
    "\n",
    "# removes rows that are not necessary to match data\n",
    "clinical_df = clinical_df.drop(clinical_df.index[0])\n",
    "clinical_df = clinical_df.drop(clinical_df.index[0])\n",
    "clinical_df.head()\n",
    "codes_df = clinical_df[['bcr_patient_uuid', 'bcr_patient_barcode']]\n",
    "#codes_df.head()\n",
    "\n",
    "uuid_list = list(codes_df['bcr_patient_uuid'])\n",
    "barcode_list = list(codes_df['bcr_patient_barcode'])\n",
    "\n",
    "print(len(uuid_list))\n",
    "print(len(barcode_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1087\n",
      "1087\n"
     ]
    }
   ],
   "source": [
    "## Reads in PAM50 labels\n",
    "\n",
    "subtype_path = \"/Users/ursulawidocki/Desktop/BreCaNet/Code/TCGA_subtypes.txt\"\n",
    "subtypes = pd.read_csv(subtype_path, delimiter = \" \")\n",
    "subtypes.head()\n",
    "\n",
    "pt_barcodes_list = list(subtypes['brca_subtypes.patient'])\n",
    "subtype_list = list(subtypes['brca_subtypes.BRCA_Subtype_PAM50'])\n",
    "\n",
    "print(len(pt_barcodes_list))\n",
    "print(len(subtype_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "714\n"
     ]
    }
   ],
   "source": [
    "## First, match the folder with the file_ids to get the corresponding cases from the metadata\n",
    "\n",
    "match_cases = list()\n",
    "\n",
    "for folder in folders_list:\n",
    "    for file in file_id:\n",
    "        if folder == file:\n",
    "            ind = file_id.index(folder)\n",
    "            match_cases.append(case_id[ind])\n",
    "\n",
    "print(len(match_cases)) # should be equivalent to number of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "714\n"
     ]
    }
   ],
   "source": [
    "## Matches case_ids from metadata with uuid and patient barcodes from clinical data\n",
    "\n",
    "match_barcodes = list()\n",
    "\n",
    "for case in match_cases:\n",
    "    for ptID in uuid_list:\n",
    "        if case == ptID.lower():\n",
    "            ind = uuid_list.index(ptID)\n",
    "            match_barcodes.append(barcode_list[ind])\n",
    "            break\n",
    "            \n",
    "print(len(match_barcodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "714\n"
     ]
    }
   ],
   "source": [
    "## Matches subtypes to their barcodes from the TCGA data\n",
    "\n",
    "match_subtypes = list()\n",
    "\n",
    "for barcode in match_barcodes:\n",
    "    ind = pt_barcodes_list.index(barcode)\n",
    "    match_subtypes.append(subtype_list[ind])\n",
    "    \n",
    "print(len(match_subtypes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "832\n",
      "714\n",
      "714\n",
      "5\n",
      "{'LumA', 'LumB', 'Basal', 'Her2', 'Normal'}\n"
     ]
    }
   ],
   "source": [
    "print(len(set(folders_list)))\n",
    "print(len(set(file_id)))\n",
    "print(len(set(case_id)))\n",
    "\n",
    "\n",
    "\n",
    "print(len(set(match_subtypes))) # there is only this many subtypes among my samples\n",
    "print((set(match_subtypes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, sort the folder IDs into their subtypes\n",
    "\n",
    "Notice that the order of folders_list is in the same order as match_subtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "## uses index of subtype label to sort folder IDs into subtypes\n",
    "\n",
    "# Luminal A samples\n",
    "lumA_samples = list()\n",
    "for i in range(0,len(match_subtypes)):\n",
    "    if match_subtypes[i]==\"LumA\":\n",
    "        lumA_samples.append(folders_list[i])\n",
    "\n",
    "# Luminal B samples\n",
    "lumB_samples = list()\n",
    "for i in range(0,len(match_subtypes)):\n",
    "    if match_subtypes[i]==\"LumB\":\n",
    "        lumB_samples.append(folders_list[i])\n",
    "\n",
    "# Basal samples\n",
    "basal_samples = list()\n",
    "for i in range(0,len(match_subtypes)):\n",
    "    if match_subtypes[i]==\"Basal\":\n",
    "        basal_samples.append(folders_list[i])\n",
    "\n",
    "# Her2 samples\n",
    "her2_samples = list()\n",
    "for i in range(0,len(match_subtypes)):\n",
    "    if match_subtypes[i]==\"Her2\":\n",
    "        her2_samples.append(folders_list[i])\n",
    "\n",
    "# Normal samples\n",
    "norm_samples = list()\n",
    "for i in range(0,len(match_subtypes)):\n",
    "    if match_subtypes[i]==\"Normal\":\n",
    "        norm_samples.append(folders_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126\n"
     ]
    }
   ],
   "source": [
    "print(len(lumB_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60483\n"
     ]
    }
   ],
   "source": [
    "# gets list of genes that are in the file\n",
    "\n",
    "geneList = list() # list of all genes that are noted in the expression files\n",
    "\n",
    "with open(dataNewFolder + '/' + indivList[0], \"r\") as file:\n",
    "    for line in file.readlines():\n",
    "        potentialGene = line.strip().split(\"\\t\")[0]\n",
    "        \n",
    "        if potentialGene[0:3] == \"ENS\":\n",
    "            newGeneName = potentialGene.strip().split(\".\")[0]\n",
    "            geneList.append(newGeneName)\n",
    "print(len(geneList))\n",
    "\n",
    "geneList_lumA = geneList\n",
    "geneList_lumB = geneList\n",
    "geneList_basal = geneList\n",
    "geneList_her2 = geneList\n",
    "geneList_norm = geneList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60483, 423)\n"
     ]
    }
   ],
   "source": [
    "## Reads through the unzipped expression files and creates the expression matrices depending on how the file\n",
    "# name matches with the folder IDs of each subtype\n",
    "\n",
    "lumA_exp = np.zeros((len(geneList), len(lumA_samples))) # exp matrix of LumA samples\n",
    "lumB_exp = np.zeros((len(geneList), len(lumB_samples))) # exp matrix of LumB samples\n",
    "basal_exp = np.zeros((len(geneList), len(basal_samples))) # exp matrix of basal samples\n",
    "her2_exp = np.zeros((len(geneList), len(her2_samples))) # exp matrix of her2 samples\n",
    "norm_exp = np.zeros((len(geneList), len(norm_samples))) # exp matrix of LumA samples\n",
    "\n",
    "print(lumA_exp.shape) # just to make sure dimensions are correct\n",
    " \n",
    "lumA_j = 0 # index of the column (sample)index of the column (sample)\n",
    "lumB_j = 0\n",
    "basal_j = 0\n",
    "her2_j = 0\n",
    "norm_j = 0\n",
    "for fileName in os.listdir(dataNewFolder):\n",
    "    if fileName == '.DS_Store' or fileName == 'MANIFEST.txt':\n",
    "        continue\n",
    "    \n",
    "    if fileName in indivList:\n",
    "        \n",
    "        temp_folder = folderIDs[indivList.index(fileName)]\n",
    "        readFile = dataNewFolder + '/' + fileName\n",
    "            \n",
    "        # adds to luminal A expression matrix\n",
    "        if temp_folder in lumA_samples:\n",
    "            \n",
    "            lumA_i = 0\n",
    "            with open(readFile, \"r\") as file:\n",
    "                for line in file.readlines():\n",
    "                    if(\"no_feature\" in line):\n",
    "                        break\n",
    "                    lumA_exp[lumA_i, lumA_j] = float(line.strip().split(\"\\t\")[1])\n",
    "                    lumA_i += 1\n",
    "                    \n",
    "                lumA_j += 1\n",
    "                        \n",
    "        # adds to luminal B expression matrix\n",
    "        if temp_folder in lumB_samples:\n",
    "            \n",
    "            lumB_i = 0\n",
    "            with open(readFile, \"r\") as file:\n",
    "                for line in file.readlines():\n",
    "                    if(\"no_feature\" in line):\n",
    "                        break\n",
    "                    lumB_exp[lumB_i, lumB_j] = float(line.strip().split(\"\\t\")[1])\n",
    "                    lumB_i += 1\n",
    "                    \n",
    "                lumB_j += 1\n",
    "        \n",
    "        # adds to basal expression matrix\n",
    "        if temp_folder in basal_samples:\n",
    "            \n",
    "            basal_i = 0\n",
    "            with open(readFile, \"r\") as file:\n",
    "                for line in file.readlines():\n",
    "                    if(\"no_feature\" in line):\n",
    "                        break\n",
    "                    basal_exp[basal_i, basal_j] = float(line.strip().split(\"\\t\")[1])\n",
    "                    basal_i += 1\n",
    "                    \n",
    "                basal_j += 1\n",
    "        \n",
    "        # adds to her2 expression matrix\n",
    "        if temp_folder in her2_samples:\n",
    "            \n",
    "            her2_i = 0\n",
    "            with open(readFile, \"r\") as file:\n",
    "                for line in file.readlines():\n",
    "                    if(\"no_feature\" in line):\n",
    "                        break\n",
    "                    her2_exp[her2_i, her2_j] = float(line.strip().split(\"\\t\")[1])\n",
    "                    her2_i += 1\n",
    "                    \n",
    "                her2_j += 1\n",
    "        \n",
    "        # adds to norm expression matrix\n",
    "        if temp_folder in norm_samples:\n",
    "            \n",
    "            norm_i = 0\n",
    "            with open(readFile, \"r\") as file:\n",
    "                for line in file.readlines():\n",
    "                    if(\"no_feature\" in line):\n",
    "                        break\n",
    "                    norm_exp[norm_i, norm_j] = float(line.strip().split(\"\\t\")[1])\n",
    "                    norm_i += 1\n",
    "                    \n",
    "                norm_j += 1\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60483, 832)\n"
     ]
    }
   ],
   "source": [
    "## Makes a giant expression matrix for TMM norm in R\n",
    "# makes a matrix where patients are columns and genes are rows\n",
    "\n",
    "all_exp = np.zeros((len(geneList), len(indivList))) # matrix with all info from subtypes\n",
    "j = 0 # index of the column (sample)\n",
    "i = 0 # index of the row (gene)\n",
    "print(all_exp.shape) # just to make sure dimensions are correct\n",
    "\n",
    "for fileName in os.listdir(dataNewFolder):\n",
    "    if fileName == '.DS_Store' or fileName == 'MANIFEST.txt':\n",
    "        continue\n",
    "        \n",
    "    if fileName in indivList:\n",
    "        temp_folder = folders_list[indivList.index(fileName)]\n",
    "        readFile = dataNewFolder + '/' + fileName\n",
    "    \n",
    "        with open(readFile, \"r\") as file:\n",
    "            for line in file.readlines():\n",
    "                if(\"no_feature\" in line):\n",
    "                        break\n",
    "                all_exp[i, j] = float(line.strip().split(\"\\t\")[1])\n",
    "                i+=1\n",
    "                \n",
    "            i = 0\n",
    "            if j != len(indivList):\n",
    "                j+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.527e+03 1.397e+03 4.948e+03 ... 3.145e+03 6.713e+03 4.680e+02]\n",
      " [3.000e+00 2.000e+00 2.100e+01 ... 4.600e+01 5.690e+02 3.000e+00]\n",
      " [2.413e+03 2.021e+03 1.668e+03 ... 3.219e+03 2.248e+03 1.825e+03]\n",
      " [3.410e+03 2.140e+03 2.220e+03 ... 2.521e+03 2.452e+03 1.494e+03]\n",
      " [1.281e+03 7.480e+02 6.120e+02 ... 9.190e+02 5.160e+02 5.970e+02]]\n"
     ]
    }
   ],
   "source": [
    "print(all_exp[0:5,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Makes the expression file\n",
    "\n",
    "PANDAexpPath = '/Users/ursulawidocki/Desktop/BreCaNet/Data/PANDAinput/all_exp_HTSeq.txt'\n",
    "geneExpFile = open(PANDAexpPath,\"w+\")\n",
    "\n",
    "large_string = match_barcodes[0]\n",
    "for f in range(1, len(match_barcodes)):\n",
    "    large_string = large_string + \"\\t\" + match_barcodes[f]\n",
    "    \n",
    "newLine = large_string + \"\\n\"\n",
    "geneExpFile.write(newLine)\n",
    "\n",
    "for i in range(0, len(geneList)):\n",
    "    newLine = geneList[i]\n",
    "    \n",
    "    for j in range(0, len(file_id)):\n",
    "        newLine = newLine + \"\\t\" + str(all_exp[i,j])\n",
    "        \n",
    "    newLine = newLine + \"\\n\"\n",
    "    geneExpFile.write(newLine)\n",
    "    \n",
    "geneExpFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Makes a reference file of file names and their subtypes\n",
    "\n",
    "ref_col_path = '/Users/ursulawidocki/Desktop/BreCaNet/Data/PANDAinput/all_labels.txt'\n",
    "refFile = open(ref_col_path,\"w+\")\n",
    "\n",
    "for i in range(0, len(match_barcodes)):\n",
    "    ref_row = match_barcodes[i] + \"\\t\" + match_subtypes[i] + \"\\n\"\n",
    "    refFile.write(ref_row)\n",
    "    \n",
    "refFile.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "714\n"
     ]
    }
   ],
   "source": [
    "print(len(set(match_barcodes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
